{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "SkVBScnlafuK",
        "AW5ajrp7arzw",
        "6hlzvPaxawo9",
        "vycqmpU4a0mL",
        "IghlAHtHa2io",
        "V_68ySkba_ca",
        "9mOJj469bA3V",
        "xXN0R2H8bG7_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Dependencies"
      ],
      "metadata": {
        "id": "SkVBScnlafuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cài torch 2.0.1 + CUDA 11.8\n",
        "!pip install torch==2.5.1+cu118 torchvision==0.20.1+cu118 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Dùng đúng phiên bản phù hợp với torch==2.0.1 và cu118 (CUDA 11.8)\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
        "!pip install torch-geometric\n",
        "!pip install numpy==1.25.2 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjBntfjX7OwN",
        "outputId": "226b3eaa-c06a-4d64-8c2a-8cfface7361c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.5.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp312-cp312-linux_x86_64.whl (838.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.3/838.3 MB\u001b[0m \u001b[31m910.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp312-cp312-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu118) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu118) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu118) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu118) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu118) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu118) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1+cu118) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1+cu118) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1+cu118) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1+cu118) (3.0.2)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 sympy-1.13.1 torch-2.5.1+cu118 torchaudio-2.5.1+cu118 torchvision-0.20.1+cu118 triton-3.1.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu118/torch_scatter-2.1.2%2Bpt25cu118-cp312-cp312-linux_x86_64.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt25cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu118/torch_sparse-0.6.18%2Bpt25cu118-cp312-cp312-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt25cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Mount Google Drive"
      ],
      "metadata": {
        "id": "AW5ajrp7arzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_h1K2mW3dKq",
        "outputId": "708ddf42-d4f4-4dab-da62-da8a1d9a0ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Navigate to Model Folder"
      ],
      "metadata": {
        "id": "6hlzvPaxawo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change directory to the shortcut folder\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/RED-GNN_backup\")\n",
        "print(\"Now in:\", os.getcwd())\n",
        "# List files in current folder\n",
        "print(\"Contain: \", os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myZ9GwGE3qa_",
        "outputId": "ddc12c5b-c5d5-4eb3-f4f4-b7dc0498e4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now in: /content/drive/.shortcut-targets-by-id/1L4ON7WudkBp-Zjzj-Fn0FGqA35djsbeR/RED-GNN_backup\n",
            "Contain:  ['inductive', 'README.md', 'transductive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Go into a subfolder (like `cd subfolder`)\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/RED-GNN_backup\")\n",
        "# os.chdir(\"transductive\")\n",
        "os.chdir(\"inductive\")\n",
        "print(\"Now in:\", os.getcwd())\n",
        "# List files in current folder\n",
        "print(\"Contain: \", os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d44e26-7bb0-4b96-a043-bc4921488653",
        "id": "hrB4kRUr4lhL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now in: /content/drive/.shortcut-targets-by-id/1L4ON7WudkBp-Zjzj-Fn0FGqA35djsbeR/RED-GNN_backup/inductive\n",
            "Contain:  ['results', 'weights', 'checkpoints', 'utils.py', 'base_model.py', 'models.py', '__pycache__', 'data', 'train.py', 'load_data.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Import Required Libraries"
      ],
      "metadata": {
        "id": "vycqmpU4a0mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "\n",
        "from collections import deque, defaultdict\n",
        "from load_data import DataLoader\n",
        "from base_model import BaseModel\n",
        "from utils import cal_ranks\n",
        "from graphviz import Source\n",
        "from IPython.display import display  # For rendering in Jupyter"
      ],
      "metadata": {
        "id": "_njvqsGq6swi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Implement KGInference - Visualization class"
      ],
      "metadata": {
        "id": "IghlAHtHa2io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KGInference:\n",
        "    def __init__(self, base_model):\n",
        "        self.base_model = base_model\n",
        "        self.model = base_model.model\n",
        "        self.loader = base_model.loader\n",
        "        self.n_rel = self.loader.n_rel\n",
        "        self.n_ent = self.loader.n_ent\n",
        "        self.n_layer = 3\n",
        "\n",
        "        self.id2entity = {v: k for k, v in self.loader.entity2id.items()}\n",
        "        self.id2relation = {v: k for k, v in self.loader.relation2id.items()}\n",
        "\n",
        "    def _get_rel_name(self, rel_id, is_inverse=False):\n",
        "        \"\"\"Return relation name, adjusting for inverse direction.\"\"\"\n",
        "        if rel_id == 2 * self.n_rel:\n",
        "            return \"self\"\n",
        "        elif rel_id >= self.n_rel:\n",
        "            base_rel = self.id2relation[rel_id - self.n_rel]\n",
        "            return base_rel if is_inverse else base_rel + \"_inv\"\n",
        "        else:\n",
        "            return self.id2relation[rel_id] + \"_inv\" if is_inverse else self.id2relation[rel_id]\n",
        "\n",
        "    def _is_reverse_relation(self, r1, r2):\n",
        "        \"\"\"Check if r1 and r2 are reverse relations (e.g., son and son_inv).\"\"\"\n",
        "        if r1 >= self.n_rel and r2 < self.n_rel:\n",
        "            return self.id2relation.get(r1 - self.n_rel) == self.id2relation.get(r2)\n",
        "        if r2 >= self.n_rel and r1 < self.n_rel:\n",
        "            return self.id2relation.get(r2 - self.n_rel) == self.id2relation.get(r1)\n",
        "        return False\n",
        "\n",
        "    def _prune_paths_to_tail(self, edges, head_id, tail_id):\n",
        "        \"\"\"Prune edges to keep all <=n_layer-hop forward paths from head to tail.\n",
        "          - Forward edges can be normal or inverse\n",
        "          - No cycles (simple paths only)\n",
        "          - No duplicate triplets (h,r,t)\n",
        "          - At most one self-edge per entity\n",
        "          - Self-edge counts as 1 hop, so effective budget = n_layer - 1 if used\n",
        "          - Every kept edge must lie on a valid head->tail path\n",
        "        \"\"\"\n",
        "\n",
        "        # Build adjacency list\n",
        "        graph = defaultdict(list)\n",
        "        for h, r, t, alpha in edges:\n",
        "            graph[h].append((t, r, alpha))\n",
        "\n",
        "        max_hops = self.n_layer\n",
        "        valid_paths = []  # store all valid paths to tail\n",
        "\n",
        "        # BFS to enumerate all simple paths from head to tail\n",
        "        queue = deque([(head_id, [head_id], 0)])  # (node, path_so_far, hop_count)\n",
        "        min_hops_to_tail = float(\"inf\")\n",
        "\n",
        "        while queue:\n",
        "            node, path, hops = queue.popleft()\n",
        "            if hops >= max_hops:\n",
        "                continue\n",
        "\n",
        "            for next_node, rel, alpha in graph[node]:\n",
        "                # Prevent cycles except self-edge\n",
        "                if next_node in path and node != next_node:\n",
        "                    continue\n",
        "\n",
        "                new_hops = hops + 1\n",
        "                if new_hops > max_hops:\n",
        "                    continue\n",
        "\n",
        "                new_path = path + [next_node]\n",
        "\n",
        "                if next_node == tail_id:\n",
        "                    # Store full path including this edge\n",
        "                    valid_paths.append((new_path, (node, rel, next_node, alpha)))\n",
        "                    min_hops_to_tail = min(min_hops_to_tail, new_hops)\n",
        "                else:\n",
        "                    queue.append((next_node, new_path, new_hops))\n",
        "\n",
        "        # Collect only edges that are part of some valid head->tail path\n",
        "        valid_edges = set()\n",
        "        for path, last_edge in valid_paths:\n",
        "            # Reconstruct edges along this path\n",
        "            for i in range(len(path) - 1):\n",
        "                h = path[i]\n",
        "                t = path[i + 1]\n",
        "                for t2, r, a in graph[h]:\n",
        "                    if t2 == t:\n",
        "                        valid_edges.add((h, r, t, a))\n",
        "            valid_edges.add(last_edge)\n",
        "\n",
        "        # ✅ Add self-loop for tail if exists and budget allows\n",
        "        if min_hops_to_tail < max_hops:\n",
        "            for h, r, t, alpha in edges:\n",
        "                if h == t == tail_id:\n",
        "                    valid_edges.add((h, r, t, alpha))\n",
        "                    break\n",
        "\n",
        "        # Deduplicate edges, keeping best alpha per (h, r, t)\n",
        "        edge_dict = defaultdict(list)\n",
        "        for h, r, t, alpha in valid_edges:\n",
        "            edge_dict[(h, r, t)].append(alpha)\n",
        "\n",
        "        pruned_edges = []\n",
        "        used_self_edges = set()\n",
        "\n",
        "        for (h, r, t), alphas in edge_dict.items():\n",
        "            best_alpha = max(alphas)\n",
        "            if h == t:\n",
        "                # Each entity allows at most 1 self-edge\n",
        "                if h not in used_self_edges:\n",
        "                    pruned_edges.append((h, r, t, best_alpha))\n",
        "                    used_self_edges.add(h)\n",
        "            else:\n",
        "                pruned_edges.append((h, r, t, best_alpha))\n",
        "\n",
        "        return pruned_edges\n",
        "\n",
        "    def predict_tail(self, head_name, rel_name, alpha=0.0):\n",
        "        if head_name not in self.loader.entity2id:\n",
        "            raise ValueError(f\"Unknown entity: {head_name}\")\n",
        "        if rel_name not in self.loader.relation2id:\n",
        "            raise ValueError(f\"Unknown relation: {rel_name}\")\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(\"Alpha must be between 0 and 1\")\n",
        "\n",
        "        head_id = self.loader.entity2id[head_name]\n",
        "        rel_id = self.loader.relation2id[rel_name]\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        # Single query forward pass with subgraph collection\n",
        "        n = 1\n",
        "        q_sub = torch.LongTensor([head_id]).cuda()\n",
        "        q_rel = torch.LongTensor([rel_id]).cuda()\n",
        "\n",
        "        h0 = torch.zeros((1, n, self.model.hidden_dim)).cuda()\n",
        "        nodes = torch.cat([torch.arange(n).unsqueeze(1).cuda(), q_sub.unsqueeze(1)], 1)\n",
        "        hidden = torch.zeros(n, self.model.hidden_dim).cuda()\n",
        "\n",
        "        all_edges_with_alpha = []\n",
        "\n",
        "        for i in range(self.model.n_layer):\n",
        "            nodes_cpu = nodes.data.cpu().numpy()\n",
        "            tail_nodes, sampled_edges, old_nodes_new_idx = self.loader.get_neighbors(nodes_cpu, mode='test')\n",
        "\n",
        "            # Extract attention weights\n",
        "            sub = sampled_edges[:, 4]\n",
        "            rel = sampled_edges[:, 2]\n",
        "            obj = sampled_edges[:, 5]\n",
        "            hs = hidden[sub]\n",
        "            hr = self.model.gnn_layers[i].rela_embed(rel)\n",
        "            r_idx = sampled_edges[:, 0]\n",
        "            h_qr = self.model.gnn_layers[i].rela_embed(q_rel)[r_idx]\n",
        "            alpha_raw = self.model.gnn_layers[i].w_alpha(\n",
        "                nn.ReLU()(self.model.gnn_layers[i].Ws_attn(hs) +\n",
        "                         self.model.gnn_layers[i].Wr_attn(hr) +\n",
        "                         self.model.gnn_layers[i].Wqr_attn(h_qr))\n",
        "            )\n",
        "            # Softmax normalization\n",
        "            alpha_weights = torch.sigmoid(alpha_raw)\n",
        "            alpha_weights = alpha_weights.detach().cpu().numpy()\n",
        "\n",
        "            # Debug attention weights\n",
        "            print(f\"Layer {i+1}: Alpha weights - Min: {alpha_weights.min():.4f}, \"\n",
        "                  f\"Max: {alpha_weights.max():.4f}, Mean: {alpha_weights.mean():.4f}, \"\n",
        "                  f\"Num edges: {len(alpha_weights)}\")\n",
        "\n",
        "            # Collect edges with attention weights\n",
        "            layer_edges = []\n",
        "            for j, e in enumerate(sampled_edges):\n",
        "                h_id, r_id, t_id = e[1].item(), e[2].item(), e[3].item()\n",
        "                alpha_value = alpha_weights[j].item()\n",
        "                if alpha_value >= alpha:\n",
        "                    layer_edges.append((h_id, r_id, t_id, alpha_value))\n",
        "\n",
        "            all_edges_with_alpha.extend(layer_edges)\n",
        "            print(f\"Layer {i+1}: {len(layer_edges)} edges after alpha={alpha} pruning\")\n",
        "\n",
        "            hidden = self.model.gnn_layers[i](q_sub, q_rel, hidden, sampled_edges, tail_nodes.size(0), old_nodes_new_idx)\n",
        "            h0 = torch.zeros(1, tail_nodes.size(0), hidden.size(1)).cuda().index_copy_(1, old_nodes_new_idx, h0)\n",
        "            hidden = self.model.dropout(hidden)\n",
        "            hidden, h0 = self.model.gate(hidden.unsqueeze(0), h0)\n",
        "            hidden = hidden.squeeze(0)\n",
        "            nodes = tail_nodes\n",
        "\n",
        "        scores = self.model.W_final(hidden).squeeze(-1)\n",
        "        scores_all = torch.zeros((n, self.n_ent)).cuda()\n",
        "        scores_all[[nodes[:, 0], nodes[:, 1]]] = scores\n",
        "\n",
        "        # Find best tail\n",
        "        scores_cpu = scores_all[0].detach().cpu().numpy()\n",
        "        best_id = np.argmax(scores_cpu)\n",
        "        best_name = self.id2entity[best_id]\n",
        "        best_score = scores_cpu[best_id]\n",
        "        best_rank = 1\n",
        "\n",
        "        # Prune dead-end, redundant paths, and duplicates\n",
        "        all_edges_with_alpha = self._prune_paths_to_tail(all_edges_with_alpha, head_id, best_id)\n",
        "\n",
        "        # Convert to subgraph — no flipping needed, since BFS handled inverses\n",
        "        subgraph = []\n",
        "        for h, r, t, _ in all_edges_with_alpha:\n",
        "            subgraph.append((self.id2entity[h],\n",
        "                            self._get_rel_name(r),\n",
        "                            self.id2entity[t]))\n",
        "\n",
        "        print(f\"Final subgraph size after alpha={alpha} and path pruning: {len(subgraph)} edges\")\n",
        "        return best_name, best_rank, best_score, subgraph\n",
        "\n",
        "    def get_info(self, head_name, rel_name, tail_name, alpha=0.0):\n",
        "        if head_name not in self.loader.entity2id:\n",
        "            raise ValueError(f\"Unknown entity: {head_name}\")\n",
        "        if tail_name not in self.loader.entity2id:\n",
        "            raise ValueError(f\"Unknown entity: {tail_name}\")\n",
        "        if rel_name not in self.loader.relation2id:\n",
        "            raise ValueError(f\"Unknown relation: {rel_name}\")\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(\"Alpha must be between 0 and 1\")\n",
        "\n",
        "        head_id = self.loader.entity2id[head_name]\n",
        "        tail_id = self.loader.entity2id[tail_name]\n",
        "        rel_id = self.loader.relation2id[rel_name]\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        # Single query forward pass with subgraph collection\n",
        "        n = 1\n",
        "        q_sub = torch.LongTensor([head_id]).cuda()\n",
        "        q_rel = torch.LongTensor([rel_id]).cuda()\n",
        "\n",
        "        h0 = torch.zeros((1, n, self.model.hidden_dim)).cuda()\n",
        "        nodes = torch.cat([torch.arange(n).unsqueeze(1).cuda(), q_sub.unsqueeze(1)], 1)\n",
        "        hidden = torch.zeros(n, self.model.hidden_dim).cuda()\n",
        "\n",
        "        all_edges_with_alpha = []\n",
        "\n",
        "        for i in range(self.model.n_layer):\n",
        "            nodes_cpu = nodes.data.cpu().numpy()\n",
        "            tail_nodes, sampled_edges, old_nodes_new_idx = self.loader.get_neighbors(nodes_cpu, mode='test')\n",
        "\n",
        "            # Extract attention weights\n",
        "            sub = sampled_edges[:, 4]\n",
        "            rel = sampled_edges[:, 2]\n",
        "            obj = sampled_edges[:, 5]\n",
        "            hs = hidden[sub]\n",
        "            hr = self.model.gnn_layers[i].rela_embed(rel)\n",
        "            r_idx = sampled_edges[:, 0]\n",
        "            h_qr = self.model.gnn_layers[i].rela_embed(q_rel)[r_idx]\n",
        "            alpha_raw = self.model.gnn_layers[i].w_alpha(\n",
        "                nn.ReLU()(self.model.gnn_layers[i].Ws_attn(hs) +\n",
        "                         self.model.gnn_layers[i].Wr_attn(hr) +\n",
        "                         self.model.gnn_layers[i].Wqr_attn(h_qr))\n",
        "            )\n",
        "            # Softmax normalization\n",
        "            alpha_weights = torch.sigmoid(alpha_raw)\n",
        "            alpha_weights = alpha_weights.detach().cpu().numpy()\n",
        "\n",
        "            # Collect edges with attention weights\n",
        "            layer_edges = []\n",
        "            for j, e in enumerate(sampled_edges):\n",
        "                h_id, r_id, t_id = e[1].item(), e[2].item(), e[3].item()\n",
        "                alpha_value = alpha_weights[j].item()\n",
        "                if alpha_value >= alpha:\n",
        "                    layer_edges.append((h_id, r_id, t_id, alpha_value))\n",
        "\n",
        "            all_edges_with_alpha.extend(layer_edges)\n",
        "\n",
        "            hidden = self.model.gnn_layers[i](q_sub, q_rel, hidden, sampled_edges, tail_nodes.size(0), old_nodes_new_idx)\n",
        "            h0 = torch.zeros(1, tail_nodes.size(0), hidden.size(1)).cuda().index_copy_(1, old_nodes_new_idx, h0)\n",
        "            hidden = self.model.dropout(hidden)\n",
        "            hidden, h0 = self.model.gate(hidden.unsqueeze(0), h0)\n",
        "            hidden = hidden.squeeze(0)\n",
        "            nodes = tail_nodes\n",
        "\n",
        "        scores = self.model.W_final(hidden).squeeze(-1)\n",
        "        scores_all = torch.zeros((n, self.n_ent)).cuda()\n",
        "        scores_all[[nodes[:, 0], nodes[:, 1]]] = scores\n",
        "\n",
        "        # Find best tail\n",
        "        scores_cpu = scores_all[0].detach().cpu().numpy()\n",
        "        score = scores_cpu[tail_id]\n",
        "        rank = np.where(np.argsort(-scores_cpu) == tail_id)[0][0] + 1\n",
        "\n",
        "        # Prune dead-end, redundant paths, and duplicates\n",
        "        all_edges_with_alpha = self._prune_paths_to_tail(all_edges_with_alpha, head_id, tail_id)\n",
        "\n",
        "        # Convert to subgraph — no flipping needed, since BFS handled inverses\n",
        "        subgraph = []\n",
        "        for h, r, t, _ in all_edges_with_alpha:\n",
        "            subgraph.append((self.id2entity[h],\n",
        "                            self._get_rel_name(r),\n",
        "                            self.id2entity[t]))\n",
        "\n",
        "        print(f\"Final subgraph size after alpha={alpha} and path pruning: {len(subgraph)} edges\")\n",
        "        return tail_name, rank, score, subgraph\n",
        "\n",
        "    def generate_random_predictions(self, num_times=10, alpha=0.0):\n",
        "        entities = list(self.loader.entity2id.keys())\n",
        "        relations = list(self.loader.relation2id.keys())\n",
        "\n",
        "        results = []\n",
        "        for _ in range(num_times):\n",
        "            rand_head = random.choice(entities)\n",
        "            rand_rel = random.choice(relations)\n",
        "            try:\n",
        "                best_tail, rank, score, subgraph = self.predict_tail(rand_head, rand_rel, alpha)\n",
        "                results.append({\n",
        "                    'head': rand_head,\n",
        "                    'relation': rand_rel,\n",
        "                    'best_tail': best_tail,\n",
        "                    'rank': rank,\n",
        "                    'score': score,\n",
        "                    'subgraph': subgraph\n",
        "                })\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        if not results:\n",
        "            raise ValueError(\"No valid random predictions generated\")\n",
        "\n",
        "        best_result = max(results, key=lambda x: x['score'])\n",
        "        return best_result\n",
        "\n",
        "    def get_random_head(self):\n",
        "        entities = list(self.loader.entity2id.keys())\n",
        "        return random.choice(entities)\n",
        "\n",
        "    def get_random_relation(self):\n",
        "        relations = list(self.loader.relation2id.keys())\n",
        "        return random.choice(relations)\n",
        "\n",
        "    def visualize_subgraph(self, subgraph, head_name, rel_name, best_tail_name):\n",
        "        # Adjacency: h -> list of (t, r)\n",
        "        adj = defaultdict(list)\n",
        "        for h, r, t in subgraph:\n",
        "            adj[h].append((t, r))\n",
        "\n",
        "        # Initialize graph\n",
        "        G = nx.DiGraph()\n",
        "\n",
        "        used_self_global = set()        # Each entity may use at most one self-edge\n",
        "        used_edges_per_layer = set()    # Dedupe per layer: (layer, h, r, t)\n",
        "        layer_nodes = defaultdict(list) # For rank grouping\n",
        "        reached_layer = {head_name: 0}  # Where each node ended up (deepest layer index)\n",
        "        layer_nodes[0].append(head_name)\n",
        "\n",
        "        # Layered frontier\n",
        "        current_layer = {head_name}\n",
        "\n",
        "        # Expand exactly self.n_layer steps; last layer index will be self.n_layer\n",
        "        for layer in range(self.n_layer):\n",
        "            next_layer = set()\n",
        "\n",
        "            # Add nodes for current layer\n",
        "            for h in current_layer:\n",
        "                h_layer = f\"{h}@{layer}\"\n",
        "                G.add_node(h_layer, label=h, layer=layer)\n",
        "\n",
        "            for h in current_layer:\n",
        "                h_layer = f\"{h}@{layer}\"\n",
        "                for t, r in adj.get(h, []):\n",
        "                    # Defer tail until final step so last layer contains only the predicted tail\n",
        "                    if layer < self.n_layer - 1 and t == best_tail_name:\n",
        "                        continue\n",
        "                    # Final step: only allow edges that go to the predicted tail\n",
        "                    if layer == self.n_layer - 1 and t != best_tail_name:\n",
        "                        continue\n",
        "\n",
        "                    # One self-edge per entity globally\n",
        "                    if h == t and h in used_self_global:\n",
        "                        continue\n",
        "\n",
        "                    key = (layer, h, r, t)\n",
        "                    if key in used_edges_per_layer:\n",
        "                        continue\n",
        "                    used_edges_per_layer.add(key)\n",
        "                    if h == t:\n",
        "                        used_self_global.add(h)\n",
        "\n",
        "                    t_layer = f\"{t}@{layer+1}\"\n",
        "                    G.add_node(t_layer, label=t, layer=layer + 1)\n",
        "                    G.add_edge(h_layer, t_layer, relation=r)\n",
        "\n",
        "                    next_layer.add(t)\n",
        "                    reached_layer[t] = max(reached_layer.get(t, -1), layer + 1)\n",
        "                    layer_nodes[layer + 1].append(t)\n",
        "\n",
        "            current_layer = next_layer\n",
        "\n",
        "        # Compute layout (position nodes by layer with reduced width for 80% edge length)\n",
        "        pos = {}\n",
        "        width = 800\n",
        "        height = 600\n",
        "        for node in G.nodes:\n",
        "            layer = G.nodes[node]['layer']\n",
        "            node_label = G.nodes[node]['label']\n",
        "            # Spread nodes horizontally by layer, vertically within layer\n",
        "            layer_size = len(layer_nodes[layer]) or 1\n",
        "            y_offset = (layer_nodes[layer].index(node_label) - (layer_size - 1) / 2) \\\n",
        "                      * (height / (layer_size + 1)) * 2\n",
        "            pos[node] = ((layer / self.n_layer) * width,\n",
        "                        height / 2 + y_offset)\n",
        "\n",
        "        # Check for predicted edge collision\n",
        "        def edges_intersect(p1, p2, q1, q2, tolerance=5):\n",
        "            def ccw(A, B, C):\n",
        "                return (C[1] - A[1]) * (B[0] - A[0]) > (B[1] - A[1]) * (C[0] - A[0])\n",
        "            def intersect(A, B, C, D):\n",
        "                return ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)\n",
        "            return intersect(p1, p2, q1, q2) and abs((p2[0] - p1[0]) * (q2[1] - q1[1]) - (q2[0] - q1[0]) * (p2[1] - p1[1])) > tolerance\n",
        "\n",
        "        pred_edge_collides = False\n",
        "        pred_edge_points = None\n",
        "        if best_tail_name in reached_layer and reached_layer[best_tail_name] == self.n_layer:\n",
        "            pred_start = pos[f\"{head_name}@0\"]\n",
        "            pred_end = pos[f\"{best_tail_name}@{self.n_layer}\"]\n",
        "            pred_edge_points = (pred_start, pred_end)\n",
        "            for edge in G.edges():\n",
        "                if edge[0] == f\"{head_name}@0\" and edge[1] == f\"{best_tail_name}@{self.n_layer}\":\n",
        "                    continue\n",
        "                start = pos[edge[0]]\n",
        "                end = pos[edge[1]]\n",
        "                if edges_intersect(pred_start, pred_end, start, end):\n",
        "                    pred_edge_collides = True\n",
        "                    break\n",
        "\n",
        "        # Create edge traces\n",
        "        edge_x = []\n",
        "        edge_y = []\n",
        "        edge_text = []\n",
        "        edge_annotations = []\n",
        "        for edge in G.edges(data=True):\n",
        "            x0, y0 = pos[edge[0]]\n",
        "            x1, y1 = pos[edge[1]]\n",
        "            edge_x.extend([x0, x1, None])\n",
        "            edge_y.extend([y0, y1, None])\n",
        "            edge_text.append(edge[2]['relation'])\n",
        "\n",
        "            # Place label directly on the edge, no rotation\n",
        "            mid_x = (x0 + x1) / 2\n",
        "            mid_y = (y0 + y1) / 2\n",
        "            edge_annotations.append(\n",
        "                dict(\n",
        "                    x=mid_x, y=mid_y,\n",
        "                    xref=\"x\", yref=\"y\",\n",
        "                    text=edge[2]['relation'],\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=15, color='black'),\n",
        "                    textangle=0,  # No rotation, always horizontal\n",
        "                    align='center',\n",
        "                    xanchor='center',\n",
        "                    yanchor='middle'\n",
        "                )\n",
        "            )\n",
        "\n",
        "        edge_trace = go.Scatter(\n",
        "            x=edge_x, y=edge_y,\n",
        "            line=dict(width=1, color='black'),\n",
        "            hoverinfo='text',\n",
        "            text=edge_text,\n",
        "            mode='lines+markers',\n",
        "            marker=dict(symbol='arrow-bar-up', size=8, angleref='previous', color='black'),\n",
        "            line_shape='spline',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        # Predicted edge trace\n",
        "        pred_edge_x = []\n",
        "        pred_edge_y = []\n",
        "        pred_edge_text = []\n",
        "        pred_edge_annotation = []\n",
        "        if best_tail_name in reached_layer and reached_layer[best_tail_name] == self.n_layer and not pred_edge_collides:\n",
        "            x0, y0 = pos[f\"{head_name}@0\"]\n",
        "            x1, y1 = pos[f\"{best_tail_name}@{self.n_layer}\"]\n",
        "            pred_edge_x = [x0, x1, None]\n",
        "            pred_edge_y = [y0, y1, None]\n",
        "            pred_edge_text = [rel_name]\n",
        "            # Place label directly on the edge, no rotation\n",
        "            mid_x = (x0 + x1) / 2\n",
        "            mid_y = (y0 + y1) / 2\n",
        "            pred_edge_annotation.append(\n",
        "                dict(\n",
        "                    x=mid_x, y=mid_y,\n",
        "                    xref=\"x\", yref=\"y\",\n",
        "                    text=rel_name,\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=15, color='red'),\n",
        "                    textangle=0,  # No rotation, always horizontal\n",
        "                    align='center',\n",
        "                    xanchor='center',\n",
        "                    yanchor='middle'\n",
        "                )\n",
        "            )\n",
        "\n",
        "        pred_edge_trace = go.Scatter(\n",
        "            x=pred_edge_x, y=pred_edge_y,\n",
        "            line=dict(width=2, color='red', dash='dash'),\n",
        "            hoverinfo='text',\n",
        "            text=pred_edge_text,\n",
        "            mode='lines+markers',\n",
        "            marker=dict(symbol='arrow-bar-up', size=8, angleref='previous', color='red'),\n",
        "            line_shape='spline',\n",
        "            name=f\"{rel_name} (predicted)\",\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        # Create node traces\n",
        "        node_x = []\n",
        "        node_y = []\n",
        "        node_text = []\n",
        "        node_colors = []\n",
        "        for node in G.nodes:\n",
        "            x, y = pos[node]\n",
        "            node_x.append(x)\n",
        "            node_y.append(y)\n",
        "            label = G.nodes[node]['label']\n",
        "            layer = G.nodes[node]['layer']\n",
        "            node_text.append(f\"{label} (Layer {layer})\")\n",
        "            if node == f\"{head_name}@0\":\n",
        "                node_colors.append('blue')\n",
        "            elif node == f\"{best_tail_name}@{self.n_layer}\":\n",
        "                node_colors.append('green')\n",
        "            else:\n",
        "                node_colors.append('lightblue')\n",
        "\n",
        "        node_trace = go.Scatter(\n",
        "            x=node_x, y=node_y,\n",
        "            mode='markers+text',\n",
        "            text=node_text,\n",
        "            textposition='top center',\n",
        "            hoverinfo='text',\n",
        "            marker=dict(\n",
        "                showscale=False,\n",
        "                color=node_colors,\n",
        "                size=10,\n",
        "                line=dict(width=2, color='white')\n",
        "            ),\n",
        "            textfont=dict(size=15),\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        # Create figure\n",
        "        annotations = edge_annotations + pred_edge_annotation\n",
        "        # Add (h, r, t) at bottom if predicted edge collides\n",
        "        if pred_edge_collides and best_tail_name in reached_layer and reached_layer[best_tail_name] == self.n_layer:\n",
        "            annotations.append(\n",
        "                dict(\n",
        "                    x=0.5, y=-0.1,\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    text=f\"Predicted: ({head_name}, {rel_name}, {best_tail_name})\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=14, color='red'),\n",
        "                    align='center'\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Find min/max x from positions\n",
        "        all_x = [coord[0] for coord in pos.values()]\n",
        "        min_x, max_x = min(all_x), max(all_x)\n",
        "\n",
        "        # Add horizontal padding (e.g., 10%)\n",
        "        padding_x = (max_x - min_x) * 0.08\n",
        "\n",
        "        fig = go.Figure(\n",
        "            data=[edge_trace, pred_edge_trace, node_trace],\n",
        "            layout=go.Layout(\n",
        "                title='Subgraph Visualization',\n",
        "                titlefont=dict(size=24),\n",
        "                showlegend=False,\n",
        "                hovermode='closest',\n",
        "                margin=dict(b=50, l=5, r=5, t=60),\n",
        "                xaxis=dict(\n",
        "                    showgrid=False, zeroline=False, showticklabels=False,\n",
        "                    range=[min_x - padding_x, max_x + padding_x],  # <-- only horizontal padding\n",
        "                ),\n",
        "                yaxis=dict(\n",
        "                    showgrid=False, zeroline=False, showticklabels=False,\n",
        "                    scaleanchor=\"x\"  # preserve aspect ratio\n",
        "                ),\n",
        "                width=800,\n",
        "                height=600,\n",
        "                plot_bgcolor='white',\n",
        "                annotations=annotations\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Show the plot\n",
        "        fig.show()\n",
        "\n",
        "        # Return HTML for embedding if needed\n",
        "        return fig.to_html()"
      ],
      "metadata": {
        "id": "PDmqu-Y3mQAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Transductive Scenario"
      ],
      "metadata": {
        "id": "V_68ySkba_ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'data/family'\n",
        "\n",
        "class Options(object):\n",
        "    pass\n",
        "\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "dataset = data_path.split('/')\n",
        "if len(dataset[-1]) > 0:\n",
        "    dataset = dataset[-1]\n",
        "else:\n",
        "    dataset = dataset[-2]\n",
        "\n",
        "save_dir = os.getcwd() + '/'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "results_dir = save_dir + 'results'\n",
        "if not os.path.exists(results_dir):\n",
        "    os.makedirs(results_dir)\n",
        "\n",
        "weights_dir = save_dir + \"weights\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.makedirs(weights_dir)\n",
        "\n",
        "checkpoint_dir = save_dir + \"checkpoints\"\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "opts = Options\n",
        "opts.perf_file = os.path.join(results_dir,  dataset + '_perf.txt')\n",
        "opts.best_weight_file = os.path.join(weights_dir, dataset + '_weight.pt')\n",
        "opts.checkpoint_weight_file = os.path.join(checkpoint_dir, dataset + '_checkpoint.pt')\n",
        "\n",
        "loader = DataLoader(data_path)\n",
        "opts.n_ent = loader.n_ent\n",
        "opts.n_rel = loader.n_rel\n",
        "\n",
        "if dataset == 'family':\n",
        "    opts.lr = 0.0036\n",
        "    opts.decay_rate = 0.999\n",
        "    opts.lamb = 0.000017\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 5\n",
        "    opts.n_layer = 3\n",
        "    opts.dropout = 0.29\n",
        "    opts.act = 'relu'\n",
        "    opts.n_batch = 20\n",
        "    opts.n_tbatch = 50\n",
        "elif dataset == 'umls':\n",
        "    opts.lr = 0.0012\n",
        "    opts.decay_rate = 0.998\n",
        "    opts.lamb = 0.00014\n",
        "    opts.hidden_dim = 64\n",
        "    opts.attn_dim = 5\n",
        "    opts.n_layer = 5\n",
        "    opts.dropout = 0.01\n",
        "    opts.act = 'tanh'\n",
        "    opts.n_batch = 10\n",
        "    opts.n_tbatch = 50\n",
        "elif dataset == 'WN18RR':\n",
        "    opts.lr = 0.0003\n",
        "    opts.decay_rate = 0.994\n",
        "    opts.lamb = 0.00014\n",
        "    opts.hidden_dim = 64\n",
        "    opts.attn_dim = 5\n",
        "    opts.n_layer = 4\n",
        "    opts.dropout = 0.02\n",
        "    opts.act = 'idd'\n",
        "    opts.n_batch = 50\n",
        "    opts.n_tbatch = 50\n",
        "elif dataset == 'fb15k-237':\n",
        "    opts.lr = 0.0009\n",
        "    opts.decay_rate = 0.9938\n",
        "    opts.lamb = 0.000080\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 5\n",
        "    opts.n_layer = 3\n",
        "    opts.dropout = 0.0391\n",
        "    opts.act = 'relu'\n",
        "    opts.n_batch = 5\n",
        "    opts.n_tbatch = 1\n",
        "elif dataset == 'nell':\n",
        "    opts.lr = 0.0011\n",
        "    opts.decay_rate = 0.9938\n",
        "    opts.lamb = 0.000089\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 5\n",
        "    opts.n_layer = 3\n",
        "    opts.dropout = 0.2593\n",
        "    opts.act = 'relu'\n",
        "    opts.n_batch = 5\n",
        "    opts.n_tbatch = 1\n",
        "\n",
        "\n",
        "\n",
        "config_str = '%.4f, %.4f, %.6f,  %d, %d, %d, %d, %.4f,%s\\n' % (opts.lr, opts.decay_rate, opts.lamb, opts.hidden_dim, opts.attn_dim, opts.n_layer, opts.n_batch, opts.dropout, opts.act)\n",
        "print(config_str)\n",
        "with open(opts.perf_file, 'a+') as f:\n",
        "    f.write(config_str)\n",
        "\n",
        "model = BaseModel(opts, loader)\n",
        "\n",
        "# start_epoch, best_mrr = model.load_checkpoint(opts.best_weight_file)\n",
        "\n",
        "# best_mrr = 0\n",
        "# for epoch in range(50):\n",
        "#     mrr, out_str = model.train_batch()\n",
        "#     with open(opts.perf_file, 'a+') as f:\n",
        "#         f.write(out_str)\n",
        "#     if mrr > best_mrr:\n",
        "#         best_mrr = mrr\n",
        "#         best_str = out_str\n",
        "#         print(str(epoch) + '\\t' + best_str)\n",
        "# print(best_str)"
      ],
      "metadata": {
        "id": "6gLwH5Mv5taD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3555138-92a8-4c5b-d3ba-d4df6190765f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train: 11736 n_valid: 3564 n_test: 4751\n",
            "0.0036, 0.9990, 0.000017,  48, 5, 3, 20, 0.2900,relu\n",
            "\n",
            "Checkpoint loaded from /content/drive/.shortcut-targets-by-id/1L4ON7WudkBp-Zjzj-Fn0FGqA35djsbeR/RED-GNN_backup/transductive/weights/family_weight.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Inductive Scenario"
      ],
      "metadata": {
        "id": "9mOJj469bA3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"data/nell_v4\"\n",
        "dataset = data_path.split('/')\n",
        "\n",
        "class Options(object):\n",
        "    pass\n",
        "\n",
        "if len(dataset[-1]) > 0:\n",
        "    dataset = dataset[-1]\n",
        "else:\n",
        "    dataset = dataset[-2]\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/RED-GNN_backup/inductive/'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "results_dir = save_dir + 'results'\n",
        "if not os.path.exists(results_dir):\n",
        "    os.makedirs(results_dir)\n",
        "\n",
        "weights_dir = save_dir + \"weights\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.makedirs(weights_dir)\n",
        "\n",
        "checkpoint_dir = save_dir + \"checkpoints\"\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "opts = Options\n",
        "opts.perf_file = os.path.join(results_dir,  dataset + '_perf.txt')\n",
        "opts.best_weight_file = os.path.join(weights_dir, dataset + '_weight.pt')\n",
        "opts.checkpoint_file = os.path.join(checkpoint_dir, dataset + '_checkpoint.pt')\n",
        "\n",
        "loader = DataLoader(data_path)\n",
        "opts.n_ent = loader.n_ent\n",
        "opts.n_rel = loader.n_rel\n",
        "\n",
        "if dataset == 'WN18RR_v1':\n",
        "    opts.lr = 0.005\n",
        "    opts.lamb = 0.0002\n",
        "    opts.decay_rate = 0.991\n",
        "    opts.hidden_dim = 64\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.21\n",
        "    opts.act = 'idd'\n",
        "    opts.n_layer = 5\n",
        "    opts.n_batch = 100\n",
        "elif dataset == 'fb237_v1':\n",
        "    opts.lr = 0.0092\n",
        "    opts.lamb = 0.0003\n",
        "    opts.decay_rate = 0.994\n",
        "    opts.hidden_dim = 32\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.23\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 3\n",
        "    opts.n_batch = 20\n",
        "elif dataset == 'nell_v1':\n",
        "    opts.lr = 0.0021\n",
        "    opts.lamb = 0.000189\n",
        "    opts.decay_rate = 0.9937\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.2460\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 5\n",
        "    opts.n_batch = 10\n",
        "\n",
        "elif dataset == 'WN18RR_v2':\n",
        "    opts.lr = 0.0016\n",
        "    opts.lamb = 0.0004\n",
        "    opts.decay_rate = 0.994\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 3\n",
        "    opts.dropout = 0.02\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 5\n",
        "    opts.n_batch = 20\n",
        "elif dataset == 'fb237_v2':\n",
        "    opts.lr = 0.0077\n",
        "    opts.lamb = 0.0002\n",
        "    opts.decay_rate = 0.993\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.3\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 3\n",
        "    opts.n_batch = 10\n",
        "elif dataset == 'nell_v2':\n",
        "    opts.lr = 0.0075\n",
        "    opts.lamb = 0.000066\n",
        "    opts.decay_rate = 0.9996\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.2881\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 3\n",
        "    opts.n_batch = 100\n",
        "\n",
        "elif dataset == 'WN18RR_v3':\n",
        "    opts.lr = 0.0014\n",
        "    opts.lamb = 0.000034\n",
        "    opts.decay_rate = 0.991\n",
        "    opts.hidden_dim = 64\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.28\n",
        "    opts.act = 'tanh'\n",
        "    opts.n_layer = 5\n",
        "    opts.n_batch = 20\n",
        "elif dataset == 'fb237_v3':\n",
        "    opts.lr = 0.0006\n",
        "    opts.lamb = 0.000023\n",
        "    opts.decay_rate = 0.994\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 3\n",
        "    opts.dropout = 0.27\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 3\n",
        "    opts.n_batch = 20\n",
        "elif dataset == 'nell_v3':\n",
        "    opts.lr = 0.0008\n",
        "    opts.lamb = 0.0004\n",
        "    opts.decay_rate = 0.995\n",
        "    opts.hidden_dim = 16\n",
        "    opts.attn_dim = 3\n",
        "    opts.dropout = 0.06\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 3\n",
        "    opts.n_batch = 10\n",
        "\n",
        "elif dataset == 'WN18RR_v4':\n",
        "    opts.lr = 0.006\n",
        "    opts.lamb = 0.000132\n",
        "    opts.decay_rate = 0.991\n",
        "    opts.hidden_dim = 32\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.11\n",
        "    opts.act = 'relu'\n",
        "    opts.n_layer = 5\n",
        "    opts.n_batch = 10\n",
        "elif dataset == 'fb237_v4':\n",
        "    opts.lr = 0.0052\n",
        "    opts.lamb = 0.000018\n",
        "    opts.decay_rate = 0.999\n",
        "    opts.hidden_dim = 48\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.07\n",
        "    opts.act = 'idd'\n",
        "    opts.n_layer = 5\n",
        "    opts.n_batch = 20\n",
        "elif dataset == 'nell_v4':\n",
        "    opts.lr = 0.0005\n",
        "    opts.lamb = 0.000398\n",
        "    opts.decay_rate = 1\n",
        "    opts.hidden_dim = 16\n",
        "    opts.attn_dim = 5\n",
        "    opts.dropout = 0.1472\n",
        "    opts.act = 'tanh'\n",
        "    opts.n_layer = 5\n",
        "    opts.n_batch = 20\n",
        "\n",
        "config_str = '%.4f, %.4f, %.6f,  %d, %d, %d, %d, %.4f,%s\\n' % (opts.lr, opts.decay_rate, opts.lamb, opts.hidden_dim, opts.attn_dim, opts.n_layer, opts.n_batch, opts.dropout, opts.act)\n",
        "print(config_str)\n",
        "\n",
        "model = BaseModel(opts, loader)\n",
        "\n",
        "# start_epoch, best_mrr = model.load_checkpoint(opts.best_weight_file)\n",
        "\n",
        "# end_epoch = 50\n",
        "# best_mrr = 0\n",
        "# for epoch in range(end_epoch):\n",
        "#     print(f\"Epoch {epoch}\")\n",
        "#     mrr, out_str = model.train_batch()\n",
        "#     with open(opts.perf_file, 'a+') as f:\n",
        "#         f.write(f'epoch {epoch}  ' + out_str)\n",
        "#     if mrr > best_mrr:\n",
        "#         best_mrr = mrr\n",
        "#         best_str = out_str\n",
        "#         print(f\"Best Epoch {epoch}:\\t{best_str}\")\n",
        "#         model.save_checkpoint(opts.best_weight_file, epoch + 1, best_mrr)\n",
        "#         print(f\"Best model saved at epoch {epoch + 1}\")\n",
        "#     if (epoch + 1) % 4 == 0:\n",
        "#         model.save_checkpoint(opts.checkpoint_file, epoch + 1, best_mrr)\n",
        "#         print(f\"Checkpoint saved at epoch {epoch + 1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gMGbMR1LWXh",
        "outputId": "df1c6477-1b29-4a2f-8234-8efd34aaccfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đường dẫn hiện tại: /content/drive/.shortcut-targets-by-id/1L4ON7WudkBp-Zjzj-Fn0FGqA35djsbeR/RED-GNN_backup/inductive\n",
            "n_train: 1752 n_valid: 1063 n_test: 1882\n",
            "0.0005, 1.0000, 0.000398,  16, 5, 5, 20, 0.1472,tanh\n",
            "\n",
            "[WARNING] Checkpoint not found at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt. Starting from scratch.\n",
            "Epoch 0\n",
            "Best Epoch 0:\t[VALID] MRR:0.0723 H@1:0.0288 H@10:0.1522\t [TEST] MRR:0.0354 H@1:0.0187 H@10:0.0622 \t[TIME] train:12.8732 inference:12.0386\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 1\n",
            "Epoch 1\n",
            "Best Epoch 1:\t[VALID] MRR:0.1130 H@1:0.0709 H@10:0.1753\t [TEST] MRR:0.0643 H@1:0.0249 H@10:0.1240 \t[TIME] train:24.9196 inference:11.7830\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 2\n",
            "Epoch 2\n",
            "Best Epoch 2:\t[VALID] MRR:0.1502 H@1:0.0854 H@10:0.2964\t [TEST] MRR:0.1301 H@1:0.0743 H@10:0.2343 \t[TIME] train:36.9394 inference:13.5304\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 3\n",
            "Epoch 3\n",
            "Best Epoch 3:\t[VALID] MRR:0.1728 H@1:0.0888 H@10:0.3679\t [TEST] MRR:0.1995 H@1:0.1282 H@10:0.3321 \t[TIME] train:48.7698 inference:11.4076\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 4\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 4\n",
            "Epoch 4\n",
            "Best Epoch 4:\t[VALID] MRR:0.1843 H@1:0.0998 H@10:0.3864\t [TEST] MRR:0.2264 H@1:0.1482 H@10:0.3683 \t[TIME] train:60.7273 inference:12.8843\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 5\n",
            "Epoch 5\n",
            "Best Epoch 5:\t[VALID] MRR:0.1918 H@1:0.0980 H@10:0.4054\t [TEST] MRR:0.2431 H@1:0.1607 H@10:0.4008 \t[TIME] train:72.7542 inference:11.9830\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 6\n",
            "Epoch 6\n",
            "Best Epoch 6:\t[VALID] MRR:0.2007 H@1:0.1038 H@10:0.4250\t [TEST] MRR:0.2456 H@1:0.1576 H@10:0.4029 \t[TIME] train:84.7445 inference:11.8865\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 7\n",
            "Epoch 7\n",
            "Best Epoch 7:\t[VALID] MRR:0.2123 H@1:0.1073 H@10:0.4354\t [TEST] MRR:0.2518 H@1:0.1631 H@10:0.4136 \t[TIME] train:96.7607 inference:11.6020\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 8\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 8\n",
            "Epoch 8\n",
            "Best Epoch 8:\t[VALID] MRR:0.2193 H@1:0.1067 H@10:0.4533\t [TEST] MRR:0.2543 H@1:0.1631 H@10:0.4178 \t[TIME] train:108.4563 inference:11.6366\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 9\n",
            "Epoch 9\n",
            "Best Epoch 9:\t[VALID] MRR:0.2350 H@1:0.1251 H@10:0.4550\t [TEST] MRR:0.2615 H@1:0.1666 H@10:0.4309 \t[TIME] train:120.6649 inference:12.0222\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 10\n",
            "Epoch 10\n",
            "Best Epoch 10:\t[VALID] MRR:0.2410 H@1:0.1292 H@10:0.4654\t [TEST] MRR:0.2615 H@1:0.1662 H@10:0.4271 \t[TIME] train:132.8762 inference:11.8673\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 11\n",
            "Epoch 11\n",
            "Best Epoch 11:\t[VALID] MRR:0.2541 H@1:0.1419 H@10:0.4694\t [TEST] MRR:0.2618 H@1:0.1693 H@10:0.4209 \t[TIME] train:144.9724 inference:11.6242\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 12\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 12\n",
            "Epoch 12\n",
            "Best Epoch 12:\t[VALID] MRR:0.2669 H@1:0.1574 H@10:0.4740\t [TEST] MRR:0.2639 H@1:0.1766 H@10:0.4088 \t[TIME] train:157.0002 inference:11.1807\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 13\n",
            "Epoch 13\n",
            "Best Epoch 13:\t[VALID] MRR:0.2836 H@1:0.1794 H@10:0.4758\t [TEST] MRR:0.2608 H@1:0.1735 H@10:0.4064 \t[TIME] train:168.7540 inference:12.0366\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 14\n",
            "Epoch 14\n",
            "Best Epoch 14:\t[VALID] MRR:0.2979 H@1:0.1990 H@10:0.4850\t [TEST] MRR:0.2660 H@1:0.1769 H@10:0.4178 \t[TIME] train:180.8049 inference:11.9655\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 15\n",
            "Epoch 15\n",
            "Best Epoch 15:\t[VALID] MRR:0.3035 H@1:0.2042 H@10:0.4787\t [TEST] MRR:0.2640 H@1:0.1735 H@10:0.4205 \t[TIME] train:192.7932 inference:11.8336\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 16\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 16\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Best Epoch 17:\t[VALID] MRR:0.3152 H@1:0.2220 H@10:0.4885\t [TEST] MRR:0.2642 H@1:0.1724 H@10:0.4205 \t[TIME] train:216.5081 inference:10.9738\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 18\n",
            "Epoch 18\n",
            "Best Epoch 18:\t[VALID] MRR:0.3253 H@1:0.2364 H@10:0.4896\t [TEST] MRR:0.2674 H@1:0.1752 H@10:0.4267 \t[TIME] train:228.5264 inference:12.0109\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 19\n",
            "Epoch 19\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 20\n",
            "Epoch 20\n",
            "Best Epoch 20:\t[VALID] MRR:0.3299 H@1:0.2376 H@10:0.4896\t [TEST] MRR:0.2629 H@1:0.1710 H@10:0.4212 \t[TIME] train:252.5550 inference:11.7947\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 21\n",
            "Epoch 21\n",
            "Best Epoch 21:\t[VALID] MRR:0.3362 H@1:0.2474 H@10:0.4983\t [TEST] MRR:0.2621 H@1:0.1697 H@10:0.4223 \t[TIME] train:264.8093 inference:11.6937\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 22\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 24\n",
            "Epoch 24\n",
            "Best Epoch 24:\t[VALID] MRR:0.3420 H@1:0.2497 H@10:0.5098\t [TEST] MRR:0.2665 H@1:0.1755 H@10:0.4195 \t[TIME] train:300.7871 inference:11.7916\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 25\n",
            "Epoch 25\n",
            "Best Epoch 25:\t[VALID] MRR:0.3452 H@1:0.2543 H@10:0.5087\t [TEST] MRR:0.2630 H@1:0.1717 H@10:0.4150 \t[TIME] train:312.8417 inference:11.7365\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 26\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Best Epoch 27:\t[VALID] MRR:0.3466 H@1:0.2578 H@10:0.5138\t [TEST] MRR:0.2687 H@1:0.1786 H@10:0.4195 \t[TIME] train:336.6879 inference:12.1383\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 28\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 28\n",
            "Epoch 28\n",
            "Best Epoch 28:\t[VALID] MRR:0.3498 H@1:0.2618 H@10:0.5133\t [TEST] MRR:0.2688 H@1:0.1797 H@10:0.4174 \t[TIME] train:348.7277 inference:11.8007\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 29\n",
            "Epoch 29\n",
            "Best Epoch 29:\t[VALID] MRR:0.3540 H@1:0.2676 H@10:0.5173\t [TEST] MRR:0.2676 H@1:0.1780 H@10:0.4188 \t[TIME] train:360.7428 inference:11.7664\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 30\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Best Epoch 31:\t[VALID] MRR:0.3545 H@1:0.2670 H@10:0.5190\t [TEST] MRR:0.2690 H@1:0.1831 H@10:0.4150 \t[TIME] train:384.2511 inference:11.7259\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 32\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 32\n",
            "Epoch 32\n",
            "Best Epoch 32:\t[VALID] MRR:0.3562 H@1:0.2687 H@10:0.5248\t [TEST] MRR:0.2694 H@1:0.1838 H@10:0.4126 \t[TIME] train:396.2158 inference:11.7118\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 33\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Best Epoch 35:\t[VALID] MRR:0.3596 H@1:0.2693 H@10:0.5288\t [TEST] MRR:0.2650 H@1:0.1762 H@10:0.4150 \t[TIME] train:432.3433 inference:11.2699\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 36\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 36\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Best Epoch 37:\t[VALID] MRR:0.3606 H@1:0.2693 H@10:0.5277\t [TEST] MRR:0.2616 H@1:0.1710 H@10:0.4126 \t[TIME] train:456.3306 inference:11.6849\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 38\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Best Epoch 39:\t[VALID] MRR:0.3632 H@1:0.2745 H@10:0.5381\t [TEST] MRR:0.2618 H@1:0.1679 H@10:0.4198 \t[TIME] train:480.3378 inference:11.8048\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 40\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 40\n",
            "Epoch 40\n",
            "Best Epoch 40:\t[VALID] MRR:0.3634 H@1:0.2757 H@10:0.5363\t [TEST] MRR:0.2582 H@1:0.1662 H@10:0.4140 \t[TIME] train:492.6909 inference:12.3567\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 41\n",
            "Epoch 41\n",
            "Best Epoch 41:\t[VALID] MRR:0.3651 H@1:0.2751 H@10:0.5398\t [TEST] MRR:0.2577 H@1:0.1669 H@10:0.4105 \t[TIME] train:504.5953 inference:11.8996\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 42\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Best Epoch 43:\t[VALID] MRR:0.3681 H@1:0.2774 H@10:0.5381\t [TEST] MRR:0.2517 H@1:0.1576 H@10:0.4039 \t[TIME] train:528.7781 inference:11.6098\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 44\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 44\n",
            "Epoch 44\n",
            "Best Epoch 44:\t[VALID] MRR:0.3700 H@1:0.2820 H@10:0.5456\t [TEST] MRR:0.2517 H@1:0.1572 H@10:0.4053 \t[TIME] train:540.7719 inference:11.1875\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 45\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Best Epoch 46:\t[VALID] MRR:0.3717 H@1:0.2849 H@10:0.5427\t [TEST] MRR:0.2495 H@1:0.1589 H@10:0.4012 \t[TIME] train:564.7613 inference:11.9802\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 47\n",
            "Epoch 47\n",
            "Best Epoch 47:\t[VALID] MRR:0.3729 H@1:0.2860 H@10:0.5456\t [TEST] MRR:0.2514 H@1:0.1645 H@10:0.3967 \t[TIME] train:576.9184 inference:11.7182\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 48\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/checkpoints/nell_v4_checkpoint.pt\n",
            "Checkpoint saved at epoch 48\n",
            "Epoch 48\n",
            "Best Epoch 48:\t[VALID] MRR:0.3743 H@1:0.2855 H@10:0.5502\t [TEST] MRR:0.2507 H@1:0.1645 H@10:0.3943 \t[TIME] train:589.0095 inference:11.2757\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 49\n",
            "Epoch 49\n",
            "Best Epoch 49:\t[VALID] MRR:0.3752 H@1:0.2878 H@10:0.5461\t [TEST] MRR:0.2523 H@1:0.1617 H@10:0.3991 \t[TIME] train:600.4957 inference:11.8527\n",
            "\n",
            "Checkpoint saved at /content/drive/MyDrive/RED-GNN_backup/inductive/weights/nell_v4_weight.pt\n",
            "Best model saved at epoch 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Visualization"
      ],
      "metadata": {
        "id": "xXN0R2H8bG7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "kg_inference = KGInference(model)"
      ],
      "metadata": {
        "id": "W-ZDriocoaEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict for a specific doublet\n",
        "head_name = \"1482\"\n",
        "rel_name = \"son\"\n",
        "# tail_name = \"1480\"\n",
        "try:\n",
        "    best_tail, rank, score, subgraph = kg_inference.predict_tail(head_name, rel_name, alpha=0.5)\n",
        "    # print(f\"Prediction for {head_name}, {rel_name}:\")\n",
        "    # print(f\"Best Tail: {best_tail}, Rank: {rank}, Score: {score:.4f}\")\n",
        "    # print(\"Subgraph:\")\n",
        "    # for h, r, t in subgraph:\n",
        "    #     print(f\"  {h} --[{r}]--> {t}\")\n",
        "\n",
        "    # Visualize\n",
        "    graph = kg_inference.visualize_subgraph(subgraph, head_name, rel_name, best_tail)\n",
        "    # display(graph)\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "v0ct9kOjTIVk",
        "outputId": "eaa8303f-e890-4c99-b217-53cb89147165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: Alpha weights - Min: 0.0000, Max: 0.0604, Mean: 0.0205, Num edges: 3\n",
            "Layer 1: 0 edges after alpha=0.5 pruning\n",
            "Layer 2: Alpha weights - Min: 0.0002, Max: 1.0000, Mean: 0.5310, Num edges: 16\n",
            "Layer 2: 9 edges after alpha=0.5 pruning\n",
            "Layer 3: Alpha weights - Min: 0.0001, Max: 1.0000, Mean: 0.9261, Num edges: 84\n",
            "Layer 3: 78 edges after alpha=0.5 pruning\n",
            "Final subgraph size after alpha=0.5 and path pruning: 19 edges\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"0f3d57ac-ba3c-4133-905a-15dc6efe6c36\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0f3d57ac-ba3c-4133-905a-15dc6efe6c36\")) {                    Plotly.newPlot(                        \"0f3d57ac-ba3c-4133-905a-15dc6efe6c36\",                        [{\"hoverinfo\":\"text\",\"line\":{\"color\":\"black\",\"shape\":\"spline\",\"width\":1},\"marker\":{\"angleref\":\"previous\",\"color\":\"black\",\"size\":8,\"symbol\":\"arrow-bar-up\"},\"mode\":\"lines+markers\",\"showlegend\":false,\"text\":[\"self\",\"nephew\",\"nephew\",\"son_inv\",\"father\",\"self\",\"father_inv\",\"mother_inv\",\"nephew\",\"uncle_inv\",\"brother\",\"son_inv\",\"mother\"],\"x\":[0.0,266.66666666666663,null,0.0,266.66666666666663,null,266.66666666666663,533.3333333333333,null,266.66666666666663,533.3333333333333,null,266.66666666666663,533.3333333333333,null,266.66666666666663,533.3333333333333,null,266.66666666666663,533.3333333333333,null,266.66666666666663,533.3333333333333,null,533.3333333333333,800.0,null,533.3333333333333,800.0,null,533.3333333333333,800.0,null,533.3333333333333,800.0,null,533.3333333333333,800.0,null],\"y\":[300.0,0.0,null,300.0,300.0,null,0.0,180.0,null,300.0,-180.0,null,300.0,-60.0,null,300.0,180.0,null,300.0,300.0,null,300.0,420.0,null,-180.0,-166.66666666666669,null,-60.0,-166.66666666666669,null,180.0,-166.66666666666669,null,300.0,-166.66666666666669,null,420.0,-166.66666666666669,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"line\":{\"color\":\"red\",\"dash\":\"dash\",\"shape\":\"spline\",\"width\":2},\"marker\":{\"angleref\":\"previous\",\"color\":\"red\",\"size\":8,\"symbol\":\"arrow-bar-up\"},\"mode\":\"lines+markers\",\"name\":\"son (predicted)\",\"showlegend\":false,\"text\":[],\"x\":[],\"y\":[],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"blue\",\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\",\"lightblue\",\"green\"],\"line\":{\"color\":\"white\",\"width\":2},\"showscale\":false,\"size\":10},\"mode\":\"markers+text\",\"showlegend\":false,\"text\":[\"1482 (Layer 0)\",\"1482 (Layer 1)\",\"1432 (Layer 1)\",\"1433 (Layer 2)\",\"1249 (Layer 2)\",\"1432 (Layer 2)\",\"1478 (Layer 2)\",\"1479 (Layer 2)\",\"1480 (Layer 3)\"],\"textfont\":{\"size\":15},\"textposition\":\"top center\",\"x\":[0.0,266.66666666666663,266.66666666666663,533.3333333333333,533.3333333333333,533.3333333333333,533.3333333333333,533.3333333333333,800.0],\"y\":[300.0,0.0,300.0,-180.0,-60.0,180.0,300.0,420.0,-166.66666666666669],\"type\":\"scatter\"}],                        {\"annotations\":[{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"self\",\"textangle\":0,\"x\":133.33333333333331,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":150.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"nephew\",\"textangle\":0,\"x\":133.33333333333331,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":300.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"nephew\",\"textangle\":0,\"x\":399.99999999999994,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":90.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"son_inv\",\"textangle\":0,\"x\":399.99999999999994,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":60.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"father\",\"textangle\":0,\"x\":399.99999999999994,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":120.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"self\",\"textangle\":0,\"x\":399.99999999999994,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":240.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"father_inv\",\"textangle\":0,\"x\":399.99999999999994,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":300.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"mother_inv\",\"textangle\":0,\"x\":399.99999999999994,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":360.0,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"nephew\",\"textangle\":0,\"x\":666.6666666666666,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":-173.33333333333334,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"uncle_inv\",\"textangle\":0,\"x\":666.6666666666666,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":-113.33333333333334,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"brother\",\"textangle\":0,\"x\":666.6666666666666,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":6.666666666666657,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"son_inv\",\"textangle\":0,\"x\":666.6666666666666,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":66.66666666666666,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"black\",\"size\":15},\"showarrow\":false,\"text\":\"mother\",\"textangle\":0,\"x\":666.6666666666666,\"xanchor\":\"center\",\"xref\":\"x\",\"y\":126.66666666666666,\"yanchor\":\"middle\",\"yref\":\"y\"},{\"align\":\"center\",\"font\":{\"color\":\"red\",\"size\":14},\"showarrow\":false,\"text\":\"Predicted: (1482, son, 1480)\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.1,\"yref\":\"paper\"}],\"height\":600,\"hovermode\":\"closest\",\"margin\":{\"b\":50,\"l\":5,\"r\":5,\"t\":60},\"plot_bgcolor\":\"white\",\"showlegend\":false,\"title\":{\"font\":{\"size\":24},\"text\":\"Subgraph Visualization\"},\"width\":800,\"xaxis\":{\"range\":[-64.0,864.0],\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"yaxis\":{\"scaleanchor\":\"x\",\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0f3d57ac-ba3c-4133-905a-15dc6efe6c36');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}